#Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rOCWhYt_6WSlvNLWVjPFT-gKC-tIbWUH
"""

!pip install selenium
!apt-get update # for Chromium
!apt install chromium-chromedriver
!cp /usr/lib/chromium-browser/chromedriver /usr/bin

import sys
sys.path.insert(0, '/usr/lib/chromium-browser/chromedriver')

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
import time
import pandas as pd
from bs4 import BeautifulSoup

# Set up Selenium for headless operation in Colab
options = Options()
options.add_argument('--headless')
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev-shm-usage')

driver = webdriver.Chrome(options=options)

base_url = "https://www.electrifying.com"
cars_data = []

# Step 1: Scrape all car cards
for page in range(1, 17):  # Pages 1 to 16
    print(f"Processing page {page}")
    url = f"{base_url}/discovery?carType=new&carEngineType=electric&page={page}"
    driver.get(url)
    time.sleep(5)

    for _ in range(3):
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(1)

    soup = BeautifulSoup(driver.page_source, 'html.parser')
    cards = soup.find_all('div', class_='car-card')

    for card in cards:
        try:
            name = card.find('h4', class_='car-card__title').text.strip()
            score_tag = card.find('div', class_='rate__number')
            score = score_tag.text.strip() if score_tag else "N/A"
            price_tag = card.find('span', class_='car-card__price')
            price = price_tag.text.strip().replace("From: ", "") if price_tag else "N/A"
            range_tag = card.find('span', class_='car-card__range')
            range_ = range_tag.text.strip().replace("Range: ", "") if range_tag else "N/A"
            link = card.find('a')['href']
            full_link = base_url + link

            cars_data.append({
                "name": name,
                "score": score,
                "price": price,
                "range ": range_,
                "url": full_link
            })
        except Exception as e:
            print(f"‚ö†Ô∏è Error parsing card: {e}")
            continue

print(f"‚úÖ Total cars found: {len(cars_data)}")

# Step 2: Scrape each car's detail page
def get_car_details(url):
    try:
        driver.get(url)
        time.sleep(3)
        detail_soup = BeautifulSoup(driver.page_source, 'html.parser')
        props = detail_soup.find_all('li', class_='property-list__item')

        battery = maxdc = miles_per_kwh = "N/A"

        for prop in props:
            text = prop.get_text(strip=True)
            if "Battery size" in text:
                battery = text.replace("Battery size:", "").strip()
            elif "Max charge rate" in text:
                maxdc = text.replace("Max charge rate:", "").strip()
            elif "Miles per kWh" in text:
                miles_per_kwh = text.replace("Miles per kWh:", "").strip()

        return battery, maxdc, miles_per_kwh

    except Exception as e:
        print(f"‚ùå Error at {url}: {e}")
        return "N/A", "N/A", "N/A"

# Step 3: Append details to each car entry
for car in cars_data:
    print(f"üîé Scraping details for: {car['name']}")
    battery, maxdc, miles_per_kwh = get_car_details(car['url'])
    car["battery_size"] = battery
    car["max_dc_charge"] = maxdc
    car["miles_per_kwh"] = miles_per_kwh

# Step 4: Save to CSV
df = pd.DataFrame(cars_data)
df.to_csv("electric_cars.csv", index=False)
print("‚úÖ Data saved to electric_cars.csv")

from google.colab import files
files.download("electric_cars.csv")

